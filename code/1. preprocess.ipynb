{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import joblib\n",
    "\n",
    "SEED = 578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playground & original concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- playground test ratio: 0.4\n",
    "- original test ratio: 0.3\n",
    "- concat test ratio: 0.38 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_train_df = pd.read_csv(\"../data/original_train.csv\")\n",
    "# playground_train_df = pd.read_csv(\"../data/playground_train.csv\").drop(columns=['id'])\n",
    "# concat_train_df = pd.concat([original_train_df, playground_train_df])\n",
    "# concat_train_df.to_csv('../data/concat_train.csv')\n",
    "\n",
    "# original_test_df = pd.read_csv(\"../data/original_test.csv\")\n",
    "# playground_test_df = pd.read_csv(\"../data/playground_test.csv\").drop(columns=['id'])\n",
    "# concat_test_df = pd.concat([original_test_df, playground_test_df])\n",
    "# concat_test_df.to_csv('../data/concat_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_train_df = pd.read_csv(\"../data/concat_train.csv\", index_col=0)\n",
    "concat_test_df = pd.read_csv(\"../data/concat_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198240 → 186681\n",
      "122879 → 115621\n"
     ]
    }
   ],
   "source": [
    "def add_gender_feature(df, lower_threshold, upper_threshold):\n",
    "    gender = pd.read_csv(\"../data/gender.csv\", index_col=0)\n",
    "\n",
    "    X_gender = gender.drop(['gender', 'oral', 'tartar', 'smoking'], axis=1)\n",
    "    y_gender = gender['gender'].map({'F': 0, 'M': 1})\n",
    "\n",
    "    folds =  RepeatedStratifiedKFold()\n",
    "    clfs = cross_validate(xgb.XGBClassifier(random_state=SEED), X_gender, y_gender, scoring='roc_auc', cv=folds, return_estimator=True)\n",
    "\n",
    "    df['gender'] = 0\n",
    "    for clf in clfs['estimator']:\n",
    "        df['gender'] += clf.predict_proba(df[[col for col in df.columns if col not in ['smoking','gender']]])[:, 1]\n",
    "    df['gender'] /= len(clfs['estimator'])\n",
    "\n",
    "\n",
    "    print(len(df), end=' → ')\n",
    "    df = df[(df['gender']>upper_threshold) | (df['gender']<lower_threshold)].reset_index(drop=True)\n",
    "    df.loc[df['gender'] > upper_threshold, 'gender'] = 1\n",
    "    df.loc[df['gender'] < lower_threshold, 'gender'] = 0\n",
    "    print(len(df))\n",
    "\n",
    "    return df\n",
    "\n",
    "concat_train_df = add_gender_feature(concat_train_df, 0.1, 0.9)\n",
    "concat_test_df = add_gender_feature(concat_test_df, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_categorical_features(df):\n",
    "    df['BMI'] = df['weight(kg)'] / ((df['height(cm)'] / 100) ** 2)\n",
    "    df['BMI_category'] = pd.cut(df['BMI'], \n",
    "                                 bins=[0, 18.5, 25, 30, 35, 40, float('inf')], \n",
    "                                 labels=['underweight', 'normal', 'overweight', 'obese-1', 'obese-2', 'obese-3'],\n",
    "                                 right=False)\n",
    "\n",
    "    df.loc[df['gender'] == 0, 'waist_category'] = pd.cut(df[df['gender'] == 0]['waist(cm)'],\n",
    "                                                      bins=[0, 80, 88, float('inf')], \n",
    "                                                      labels=['low', 'high', 'very high'])\n",
    "    df.loc[df['gender'] == 1, 'waist_category'] = pd.cut(df[df['gender'] == 1]['waist(cm)'],\n",
    "                                                      bins=[0, 94, 102, float('inf')], \n",
    "                                                      labels=['low', 'high', 'very high'])\n",
    "\n",
    "    df['age_category'] = df['age'].apply(lambda x: 'high' if x >= 45 else 'low')\n",
    "\n",
    "    df['BP_category'] = 'normal'\n",
    "    df.loc[(df['systolic'] >= 120) & (df['systolic'] < 130) | (df['relaxation'] >= 80) & (df['relaxation'] < 89), 'BP_category'] = 'elevated'\n",
    "    df.loc[(df['systolic'] >= 130) & (df['systolic'] < 140) | (df['relaxation'] >= 90) & (df['relaxation'] < 99), 'BP_category'] = 'high BP stage 1'\n",
    "    df.loc[(df['systolic'] >= 140) & (df['systolic'] < 180) | (df['relaxation'] >= 100) & (df['relaxation'] < 120), 'BP_category'] = 'high BP stage 2'\n",
    "    df.loc[(df['systolic'] >= 180) | (df['relaxation'] >= 120), 'BP_category'] = 'high BP stage 3'\n",
    "\n",
    "    df['Cholesterol_category'] = pd.cut(df['Cholesterol'],\n",
    "                                     bins=[0, 200, 239, float('inf')],\n",
    "                                     labels=['desirable', 'borderline high', 'high'],\n",
    "                                     right=False)\n",
    "\n",
    "    df['HDL_category'] = pd.cut(df['HDL'],\n",
    "                             bins=[0, 40, 60, float('inf')],\n",
    "                             labels=['high', 'normal', 'low'],\n",
    "                             right=False)\n",
    "\n",
    "    df['LDL_category'] = pd.cut(df['LDL'],\n",
    "                             bins=[0, 100, 129, 159, 189, float('inf')],\n",
    "                             labels=['optimal', 'near optimal', 'borderline high', 'high', 'very high'],\n",
    "                             right=False)\n",
    "\n",
    "    df['triglyceride_category'] = pd.cut(df['triglyceride'],\n",
    "                                      bins=[0, 150, 199, 499, float('inf')],\n",
    "                                      labels=['normal', 'moderate', 'high', 'very high'],\n",
    "                                      right=False)\n",
    "\n",
    "    df['hemoglobin_category'] = df.apply(lambda x: 'high' if (x['hemoglobin'] < 110 if x['age'] < 5 or x['gender'] == 0 else x['hemoglobin'] < 120) else 'normal', axis=1)\n",
    "\n",
    "    df['serum creatinine_category'] = df.apply(lambda x: 'normal' if (0.74 <= x['serum creatinine'] <= 1.35 if x['gender'] == 1 else 0.59 <= x['serum creatinine'] <= 1.04) else 'abnormal', axis=1)\n",
    " \n",
    "    df['Gtp_category'] = df['Gtp'].apply(lambda x: 'normal' if 5 <= x <= 40 else 'abnormal')\n",
    "\n",
    "    df['AST_category'] = df['AST'].apply(lambda x: 'normal' if 8 <= x <= 45 else 'abnormal')\n",
    "\n",
    "    df['ALT_category'] = df['ALT'].apply(lambda x: 'normal' if 8 <= x <= 45 else 'abnormal')\n",
    "\n",
    "    return df\n",
    "\n",
    "concat_train_df = add_categorical_features(concat_train_df)\n",
    "concat_test_df = add_categorical_features(concat_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical features one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'hearing(left)',\n",
    "    'hearing(right)',\n",
    "    'Urine protein',\n",
    "    'dental caries',\n",
    "    'BMI_category',\n",
    "    'waist_category',\n",
    "    'age_category',\n",
    "    'BP_category',\n",
    "    'Cholesterol_category',\n",
    "    'HDL_category',\n",
    "    'LDL_category',\n",
    "    'triglyceride_category',\n",
    "    'hemoglobin_category',\n",
    "    'serum creatinine_category',\n",
    "    'Gtp_category',\n",
    "    'AST_category',\n",
    "    'ALT_category'\n",
    "]\n",
    "\n",
    "concat_train_df = pd.get_dummies(concat_train_df, columns=categorical_features)\n",
    "concat_test_df = pd.get_dummies(concat_test_df, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continuous features standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [feature for feature in concat_train_df.columns if feature not in categorical_features and feature != 'smoking']\n",
    "\n",
    "def fit_scaler(train_df, continuous_features, method):\n",
    "    if method == 'zscore':\n",
    "        scaler = StandardScaler()\n",
    "    elif method == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif method == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "\n",
    "    scaler.fit(train_df[continuous_features])\n",
    "\n",
    "    return scaler\n",
    "\n",
    "scaler = fit_scaler(concat_train_df, continuous_features, 'minmax')\n",
    "\n",
    "concat_train_df[continuous_features] = scaler.transform(concat_train_df[continuous_features])\n",
    "concat_test_df[continuous_features] = scaler.transform(concat_test_df[continuous_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat train → train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(concat_train_df, \n",
    "                                      test_size=0.4, \n",
    "                                      stratify=concat_train_df['smoking'], \n",
    "                                      random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, col, method):\n",
    "    percentile_25 = df[col].quantile(0.25)\n",
    "    percentile_75 = df[col].quantile(0.75)\n",
    "\n",
    "    iqr = percentile_75 - percentile_25\n",
    "\n",
    "    upper_limit = percentile_75 + 1.5 * iqr\n",
    "    lower_limit = percentile_25 - 1.5 * iqr\n",
    "\n",
    "    if method == 'replace':\n",
    "        df.loc[df[col] > upper_limit, col] = upper_limit\n",
    "        df.loc[df[col] < lower_limit, col] = lower_limit\n",
    "    elif method == 'remove':\n",
    "        df = df[(df[col] >= lower_limit) & (df[col] <= upper_limit)]\n",
    "\n",
    "    return df\n",
    "\n",
    "for col in continuous_features:\n",
    "    train_df = handle_outliers(train_df, col, 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handle skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_skewness(df, col, method):\n",
    "    if method == 'log':\n",
    "        df[col] = np.log1p(df[col])\n",
    "    elif method == 'boxcox':\n",
    "        df[col], _ = boxcox(df[col])\n",
    "        \n",
    "    return df\n",
    "\n",
    "for col in continuous_features:\n",
    "    train_df = handle_skewness(train_df, col, 'log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/preprocess_train.csv')\n",
    "valid_df.to_csv('../data/preprocess_valid.csv')\n",
    "concat_test_df.to_csv('../data/preprocess_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../fold/10_train_stratifiedkfolds.jl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folds = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(train_df, train_df['smoking']))\n",
    "joblib.dump(train_folds, f'../fold/{n_splits}_train_stratifiedkfolds.jl')\n",
    "\n",
    "valid_folds = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(valid_df, valid_df['smoking']))\n",
    "joblib.dump(valid_folds, f'../fold/{n_splits}_valid_stratifiedkfolds.jl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
