{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import joblib\n",
    "\n",
    "SEED = 578\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playground & original concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- playground test ratio: 0.4\n",
    "- original test ratio: 0.3\n",
    "- concat test ratio: 0.38 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198240\n",
      "192723\n"
     ]
    }
   ],
   "source": [
    "original_train_df = pd.read_csv(\"../data/original_train.csv\")\n",
    "original_train_df['original'] = 1\n",
    "playground_train_df = pd.read_csv(\"../data/playground_train.csv\").drop(columns=['id'])\n",
    "playground_train_df['original'] = 0\n",
    "concat_train_df = pd.concat([original_train_df[[col for col in original_train_df.columns if col != 'original']], playground_train_df[[col for col in original_train_df.columns if col != 'original']]]).drop_duplicates().reset_index(drop=True)\n",
    "concat_train_df.to_csv('../data/concat_train.csv')\n",
    "\n",
    "# original_test_df = pd.read_csv(\"../data/original_test.csv\")\n",
    "# playground_test_df = pd.read_csv(\"../data/playground_test.csv\").drop(columns=['id'])\n",
    "# concat_test_df = pd.concat([original_test_df, playground_test_df])\n",
    "# concat_test_df.to_csv('../data/concat_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/concat_train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"../data/playground_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_continuous_features(df):\n",
    "    gender = pd.read_csv(\"../data/gender.csv\", index_col=0)\n",
    "    X_gender = gender.drop(['gender', 'oral', 'tartar', 'smoking'], axis=1)\n",
    "    y_gender = gender['gender'].map({'F': 0, 'M': 1})\n",
    "    folds =  RepeatedStratifiedKFold()\n",
    "    clfs = cross_validate(xgb.XGBClassifier(random_state=SEED), X_gender, y_gender, scoring='roc_auc', cv=folds, return_estimator=True)\n",
    "    df['gender'] = 0\n",
    "    for clf in clfs['estimator']:\n",
    "        df['gender'] += clf.predict_proba(df[[col for col in df.columns if col not in ['smoking','gender']]])[:, 1]\n",
    "    df['gender'] /= len(clfs['estimator'])\n",
    "\n",
    "    df['BMI'] = df['weight(kg)'] / ((df['height(cm)'] / 100) ** 2)\n",
    "\n",
    "    best_hearing = np.where(df['hearing(left)'] < df['hearing(right)'], \n",
    "                    df['hearing(left)'],  df['hearing(right)'])\n",
    "    worst_hearing = np.where(df['hearing(left)'] < df['hearing(right)'], \n",
    "                     df['hearing(right)'],  df['hearing(left)'])\n",
    "    df['hearing(left)'] = best_hearing - 1\n",
    "    df['hearing(right)'] = worst_hearing - 1\n",
    "    \n",
    "    df['eyesight(left)'] = np.where(df['eyesight(left)'] > 9, 0, df['eyesight(left)'])\n",
    "    df['eyesight(right)'] = np.where(df['eyesight(right)'] > 9, 0, df['eyesight(right)'])\n",
    "    best_eyesight = np.where(df['eyesight(left)'] < df['eyesight(right)'], \n",
    "                    df['eyesight(left)'],  df['eyesight(right)'])\n",
    "    worst_eyesight = np.where(df['eyesight(left)'] < df['eyesight(right)'], \n",
    "                     df['eyesight(right)'],  df['eyesight(left)'])\n",
    "    df['eyesight(left)'] = best_eyesight\n",
    "    df['eyesight(right)'] = worst_eyesight\n",
    "    \n",
    "    df['Gtp'] = np.clip(df['Gtp'], 0, 300)\n",
    "    df['HDL'] = np.clip(df['HDL'], 0, 110)\n",
    "    df['LDL'] = np.clip(df['LDL'], 0, 200)\n",
    "    df['ALT'] = np.clip(df['ALT'], 0, 150)\n",
    "    df['AST'] = np.clip(df['AST'], 0, 100)\n",
    "    df['serum creatinine'] = np.clip(df['serum creatinine'], 0, 3)  \n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = add_continuous_features(train_df)\n",
    "test_df = add_continuous_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_categorical_features(df):\n",
    "    df['BMI_category'] = pd.cut(df['BMI'], \n",
    "                                 bins=[0, 18.5, 25, 30, 35, 40, float('inf')], \n",
    "                                 labels=['underweight', 'normal', 'overweight', 'obese-1', 'obese-2', 'obese-3'],\n",
    "                                 right=False)\n",
    "\n",
    "    df['approx_gender'] = np.where(df['gender'] < 0.5, 0, 1)\n",
    "    df.loc[df['approx_gender'] == 0, 'waist_category'] = pd.cut(df[df['gender'] == 0]['waist(cm)'],\n",
    "                                                      bins=[0, 80, 88, float('inf')], \n",
    "                                                      labels=['low', 'high', 'very high'])\n",
    "    df.loc[df['approx_gender'] == 1, 'waist_category'] = pd.cut(df[df['gender'] == 1]['waist(cm)'],\n",
    "                                                      bins=[0, 94, 102, float('inf')], \n",
    "                                                      labels=['low', 'high', 'very high'])\n",
    "    df.drop('approx_gender', axis=1, inplace=True)\n",
    "\n",
    "    df['age_category'] = df['age'].apply(lambda x: 'high' if x >= 45 else 'low')\n",
    "\n",
    "    df['BP_category'] = 'normal'\n",
    "    df.loc[(df['systolic'] >= 120) & (df['systolic'] < 130) | (df['relaxation'] >= 80) & (df['relaxation'] < 89), 'BP_category'] = 'elevated'\n",
    "    df.loc[(df['systolic'] >= 130) & (df['systolic'] < 140) | (df['relaxation'] >= 90) & (df['relaxation'] < 99), 'BP_category'] = 'high BP stage 1'\n",
    "    df.loc[(df['systolic'] >= 140) & (df['systolic'] < 180) | (df['relaxation'] >= 100) & (df['relaxation'] < 120), 'BP_category'] = 'high BP stage 2'\n",
    "    df.loc[(df['systolic'] >= 180) | (df['relaxation'] >= 120), 'BP_category'] = 'high BP stage 3'\n",
    "\n",
    "    df['Cholesterol_category'] = pd.cut(df['Cholesterol'],\n",
    "                                     bins=[0, 200, 239, float('inf')],\n",
    "                                     labels=['desirable', 'borderline high', 'high'],\n",
    "                                     right=False)\n",
    "\n",
    "    df['HDL_category'] = pd.cut(df['HDL'],\n",
    "                             bins=[0, 40, 60, float('inf')],\n",
    "                             labels=['high', 'normal', 'low'],\n",
    "                             right=False)\n",
    "\n",
    "    df['LDL_category'] = pd.cut(df['LDL'],\n",
    "                             bins=[0, 100, 129, 159, 189, float('inf')],\n",
    "                             labels=['optimal', 'near optimal', 'borderline high', 'high', 'very high'],\n",
    "                             right=False)\n",
    "\n",
    "    df['triglyceride_category'] = pd.cut(df['triglyceride'],\n",
    "                                      bins=[0, 150, 199, 499, float('inf')],\n",
    "                                      labels=['normal', 'moderate', 'high', 'very high'],\n",
    "                                      right=False)\n",
    "\n",
    "    df['hemoglobin_category'] = df.apply(lambda x: 'high' if (x['hemoglobin'] < 110 if x['age'] < 5 or x['gender'] == 0 else x['hemoglobin'] < 120) else 'normal', axis=1)\n",
    "\n",
    "    df['serum creatinine_category'] = df.apply(lambda x: 'normal' if (0.74 <= x['serum creatinine'] <= 1.35 if x['gender'] == 1 else 0.59 <= x['serum creatinine'] <= 1.04) else 'abnormal', axis=1)\n",
    " \n",
    "    df['Gtp_category'] = df['Gtp'].apply(lambda x: 'normal' if 5 <= x <= 40 else 'abnormal')\n",
    "\n",
    "    df['AST_category'] = df['AST'].apply(lambda x: 'normal' if 8 <= x <= 45 else 'abnormal')\n",
    "\n",
    "    df['ALT_category'] = df['ALT'].apply(lambda x: 'normal' if 8 <= x <= 45 else 'abnormal')\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = add_categorical_features(train_df)\n",
    "test_df = add_categorical_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add kmeans features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = [\n",
    "    'hearing(left)',\n",
    "    'hearing(right)',\n",
    "    'Urine protein',\n",
    "    'dental caries',\n",
    "    'BMI_category',\n",
    "    'waist_category',\n",
    "    'age_category',\n",
    "    'BP_category',\n",
    "    'Cholesterol_category',\n",
    "    'HDL_category',\n",
    "    'LDL_category',\n",
    "    'triglyceride_category',\n",
    "    'hemoglobin_category',\n",
    "    'serum creatinine_category',\n",
    "    'Gtp_category',\n",
    "    'AST_category',\n",
    "    'ALT_category'\n",
    "]\n",
    "continuous_features = [feature for feature in train_df.columns if feature not in categorical_features and feature != 'smoking']\n",
    "\n",
    "def add_kmeans_features(df, continuous_features, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=SEED).fit(df[continuous_features])\n",
    "    \n",
    "    df['kmeans_cluster_label'] = kmeans.labels_\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = add_kmeans_features(train_df, continuous_features, 3)\n",
    "test_df = add_kmeans_features(test_df, continuous_features, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical features one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df, columns=[col for col in train_df.columns if col in categorical_features])\n",
    "test_df = pd.get_dummies(test_df, columns=[col for col in test_df.columns if col in categorical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continuous features standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_scaler(train_df, continuous_features, method):\n",
    "#     if method == 'zscore':\n",
    "#         scaler = StandardScaler()\n",
    "#     elif method == 'minmax':\n",
    "#         scaler = MinMaxScaler()\n",
    "#     elif method == 'robust':\n",
    "#         scaler = RobustScaler()\n",
    "\n",
    "#     scaler.fit(train_df[continuous_features])\n",
    "\n",
    "#     return scaler\n",
    "\n",
    "# scaler = fit_scaler(train_df, continuous_features, 'minmax')\n",
    "\n",
    "# train_df[continuous_features] = scaler.transform(train_df[continuous_features])\n",
    "# test_df[continuous_features] = scaler.transform(test_df[continuous_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train → train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_df, \n",
    "                                      test_size=0.4, \n",
    "                                      stratify=train_df['smoking'], \n",
    "                                      random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, col, method):\n",
    "    percentile_25 = df[col].quantile(0.25)\n",
    "    percentile_75 = df[col].quantile(0.75)\n",
    "\n",
    "    iqr = percentile_75 - percentile_25\n",
    "\n",
    "    upper_limit = percentile_75 + 1.5 * iqr\n",
    "    lower_limit = percentile_25 - 1.5 * iqr\n",
    "\n",
    "    if method == 'replace':\n",
    "        df.loc[df[col] > upper_limit, col] = upper_limit\n",
    "        df.loc[df[col] < lower_limit, col] = lower_limit\n",
    "    elif method == 'remove':\n",
    "        df = df[(df[col] >= lower_limit) & (df[col] <= upper_limit)]\n",
    "\n",
    "    return df\n",
    "\n",
    "for col in continuous_features:\n",
    "    train_df = handle_outliers(train_df, col, 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/preprocess_train.csv')\n",
    "valid_df.to_csv('../data/preprocess_valid.csv')\n",
    "test_df.to_csv('../data/preprocess_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../fold/20_train_stratifiedkfolds.jl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folds = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(train_df, train_df['smoking']))\n",
    "joblib.dump(train_folds, f'../fold/{n_splits}_train_stratifiedkfolds.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
