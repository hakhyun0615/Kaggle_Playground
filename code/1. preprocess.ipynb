{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "import joblib\n",
    "\n",
    "SEED = 578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playground & original concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_train_df = pd.read_csv(\"../data/original_train.csv\")\n",
    "# playground_train_df = pd.read_csv(\"../data/playground_train.csv\").drop(columns=['id'])\n",
    "# concat_train_df = pd.concat([original_train_df, playground_train_df])\n",
    "# concat_train_df.to_csv('../data/concat_train.csv')\n",
    "\n",
    "# original_test_df = pd.read_csv(\"../data/original_test.csv\")\n",
    "# playground_test_df = pd.read_csv(\"../data/playground_test.csv\").drop(columns=['id'])\n",
    "# concat_test_df = pd.concat([original_test_df, playground_test_df])\n",
    "# concat_test_df.to_csv('../data/concat_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_train_df = pd.read_csv(\"../data/concat_train.csv\", index_col=0)\n",
    "concat_test_df = pd.read_csv(\"../data/concat_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    df['BMI'] = df['weight(kg)'] / ((df['height(cm)'] / 100) ** 2)\n",
    "    return df\n",
    "\n",
    "concat_train_df = add_features(concat_train_df)\n",
    "concat_test_df = add_features(concat_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical features one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['hearing(left)','hearing(right)','Urine protein','dental caries']\n",
    "\n",
    "concat_train_df = pd.get_dummies(concat_train_df, columns=categorical_features)\n",
    "concat_test_df = pd.get_dummies(concat_test_df, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continuous features standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'height(cm)',\n",
       " 'weight(kg)',\n",
       " 'waist(cm)',\n",
       " 'eyesight(left)',\n",
       " 'eyesight(right)',\n",
       " 'systolic',\n",
       " 'relaxation',\n",
       " 'fasting blood sugar',\n",
       " 'Cholesterol',\n",
       " 'triglyceride',\n",
       " 'HDL',\n",
       " 'LDL',\n",
       " 'hemoglobin',\n",
       " 'serum creatinine',\n",
       " 'AST',\n",
       " 'ALT',\n",
       " 'Gtp',\n",
       " 'BMI']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_features = [feature for feature in concat_train_df.columns if feature not in categorical_features and feature != 'smoking']\n",
    "\n",
    "def standarize_features(df, features, method):\n",
    "    if method == 'zscore':\n",
    "        scaler = StandardScaler()\n",
    "    elif method == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif method == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "\n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "    return df\n",
    "\n",
    "concat_train_df = standarize_features(concat_train_df, continuous_features, 'minmax')\n",
    "concat_test_df = standarize_features(concat_test_df, continuous_features, 'minmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, col, method):\n",
    "    percentile_25 = df[col].quantile(0.25)\n",
    "    percentile_75 = df[col].quantile(0.75)\n",
    "\n",
    "    iqr = percentile_75 - percentile_25\n",
    "\n",
    "    upper_limit = percentile_75 + 1.5 * iqr\n",
    "    lower_limit = percentile_25 - 1.5 * iqr\n",
    "\n",
    "    if method == 'replace':\n",
    "        df.loc[df[col] > upper_limit, col] = upper_limit\n",
    "        df.loc[df[col] < lower_limit, col] = lower_limit\n",
    "    elif method == 'remove':\n",
    "        df = df[(df[col] >= lower_limit) & (df[col] <= upper_limit)]\n",
    "\n",
    "    return df\n",
    "\n",
    "for col in continuous_features:\n",
    "    concat_train_df = handle_outliers(concat_train_df, col, 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handle skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_skewness(df, col, method):\n",
    "    if method == 'log':\n",
    "        df[col] = np.log1p(df[col])\n",
    "    elif method == 'boxcox':\n",
    "        df[col], _ = boxcox(df[col])\n",
    "        \n",
    "    return df\n",
    "\n",
    "for col in continuous_features:\n",
    "    concat_train_df = handle_skewness(concat_train_df, col, 'log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_train_df.to_csv('../data/preprocess_train.csv')\n",
    "concat_test_df.to_csv('../data/preprocess_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stratifiedkfolds(df, n_splits):\n",
    "    folds = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(df, df['smoking']))\n",
    "    joblib.dump(folds, f'../data/fold/{n_splits}_stratifiedkfolds.jl')\n",
    "\n",
    "save_stratifiedkfolds(concat_train_df, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
