{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SEED = 578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv', index_col=0)\n",
    "test_df = pd.read_csv('../data/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optuna hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(objective, n_trials):\n",
    "    optuna.logging.set_verbosity(optuna.logging.CRITICAL)\n",
    "    study = optuna.create_study(direction = \"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    print(\"Best Score:\", study.best_value)\n",
    "    print(\"Best Parameters:\", study.best_params)\n",
    "    return study\n",
    "\n",
    "def plot_study(study):\n",
    "    optuna.visualization.plot_optimization_history(study)\n",
    "    optuna.visualization.plot_parallel_coordinate(study)\n",
    "    optuna.visualization.plot_contour(study)\n",
    "    optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_objective(trial):\n",
    "    hyperparams = {\n",
    "        'n_estimators' : trial.suggest_int('n_estimators',500,1000),\n",
    "        \"max_depth\":trial.suggest_int('max_depth',3,50),\n",
    "        \"learning_rate\" : trial.suggest_float('learning_rate',1e-4, 0.25, log=True),\n",
    "        \"min_child_weight\" : trial.suggest_float('min_child_weight', 0.5,4),\n",
    "        \"min_child_samples\" : trial.suggest_int('min_child_samples',1,250),\n",
    "        \"subsample\" : trial.suggest_float('subsample', 0.2, 1),\n",
    "        \"subsample_freq\" : trial.suggest_int('subsample_freq',0,5),\n",
    "        \"colsample_bytree\" : trial.suggest_float('colsample_bytree',0.2,1),\n",
    "        'num_leaves' : trial.suggest_int('num_leaves', 2, 128),\n",
    "    }\n",
    "    \n",
    "    X = train_df.drop(['smoking'], axis=1)\n",
    "    y = train_df['smoking']\n",
    "\n",
    "    lgbm_model = lgb.LGBMClassifier(**hyperparams, random_state=SEED, device=\"gpu\")\n",
    "\n",
    "    aucs = cross_val_score(lgbm_model, X, y, cv = 5, scoring='roc_auc')\n",
    "    auc_mean = aucs.mean()\n",
    "\n",
    "    print(\"AUCs:\", aucs)\n",
    "    print(\"AUC Mean:\", auc_mean)\n",
    "\n",
    "    return auc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_study = optimize_hyperparameters(lgbm_objective, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgbm_hyperparams =  {\n",
    "    'n_estimators'          : 2048,\n",
    "    'max_depth'             : 9,\n",
    "    'learning_rate'         : 0.05,\n",
    "    'booster'               : 'gbtree',\n",
    "    'subsample'             : 0.75,\n",
    "    'colsample_bytree'      : 0.30,\n",
    "    'reg_lambda'            : 1.00,\n",
    "    'reg_alpha'             : 1.00,\n",
    "    'gamma'                 : 1.00,\n",
    "    'objective'             : 'binary:logistic',\n",
    "    'tree_method'           : 'hist',\n",
    "    'eval_metric'           : 'auc',\n",
    "    'n_jobs'                : -1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective(trial):\n",
    "    hyperparams = {\n",
    "        'n_estimators' : trial.suggest_int('n_estimators',500,750),\n",
    "        'max_depth':  trial.suggest_int('max_depth',3,50),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 2,50),\n",
    "        \"learning_rate\" : trial.suggest_float('learning_rate',1e-4, 0.2,log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.2, 1),\n",
    "        'gamma': trial.suggest_float(\"gamma\", 1e-4, 1.0),\n",
    "        \"colsample_bytree\" : trial.suggest_float('colsample_bytree',0.2,1),\n",
    "        \"colsample_bylevel\" : trial.suggest_float('colsample_bylevel',0.2,1),\n",
    "        \"colsample_bynode\" : trial.suggest_float('colsample_bynode',0.2,1),\n",
    "    }\n",
    "\n",
    "    X = train_df.drop(['smoking'], axis=1)\n",
    "    y = train_df['smoking']\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(**hyperparams, random_state=SEED, device=\"gpu\")\n",
    "\n",
    "    aucs = cross_val_score(xgb_model, X, y, cv = 5, scoring='roc_auc')\n",
    "    auc_mean = aucs.mean()\n",
    "\n",
    "    print(\"AUCs:\", aucs)\n",
    "    print(\"AUC Mean:\", auc_mean)\n",
    " \n",
    "    # folds = joblib.load('../data/fold/5_stratifiedkfolds.jl')\n",
    "    # fold_aucs = []\n",
    "    # fold = 1\n",
    "\n",
    "    # for train_index, val_index in folds:\n",
    "    #     print(f'Training Fold {fold}: ...\\n')\n",
    "    #     X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    #     y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    #     xgb_model.fit(X_train,\n",
    "    #               y_train,\n",
    "    #               eval_set = [(X_val, y_val)],\n",
    "    #               verbose = 0)\n",
    "        \n",
    "    #     # best_iteration = model.get_booster().best_ntree_limit\n",
    "\n",
    "    #     y_pred = model.predict_proba(X_val)[:,1] # ntree_limit=best_iteration\n",
    "        \n",
    "    #     fold_auc = roc_auc_score(y_val, y_pred)\n",
    "    #     fold_aucs.append(fold_auc)\n",
    "    #     fold += 1 \n",
    "\n",
    "    # fold_auc_mean = sum(fold_aucs) / len(fold_aucs)\n",
    "\n",
    "    # print(\"Hyperparameters:\", hyperparams)\n",
    "    # print(\"AUCs:\", fold_aucs)\n",
    "    # print(\"AUC Mean:\", fold_auc_mean)\n",
    "\n",
    "    return auc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xj/_swws2td1j333fqkjhr5tmjr0000gn/T/ipykernel_1638/83369294.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n",
      "/var/folders/xj/_swws2td1j333fqkjhr5tmjr0000gn/T/ipykernel_1638/83369294.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0.01, 1.0] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
      "  warnings.warn(\n",
      "/var/folders/xj/_swws2td1j333fqkjhr5tmjr0000gn/T/ipykernel_1638/83369294.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1: ...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb 셀 5\u001b[0m line \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m optimize_hyperparameters(xgb_objective, \u001b[39m10\u001b[39m)\n",
      "\u001b[1;32m/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb 셀 5\u001b[0m line \u001b[0;36moptimize_hyperparameters\u001b[0;34m(objective, n_trials)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mset_verbosity(optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mCRITICAL)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(objective, n_trials\u001b[39m=\u001b[39mn_trials)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Score:\u001b[39m\u001b[39m\"\u001b[39m, study\u001b[39m.\u001b[39mbest_value)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Parameters:\u001b[39m\u001b[39m\"\u001b[39m, study\u001b[39m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39m\u001b[39mtuple\u001b[39m(catch) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(catch, Iterable) \u001b[39melse\u001b[39;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb 셀 5\u001b[0m line \u001b[0;36mxgb_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m X_train, X_val \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[train_index], X\u001b[39m.\u001b[39miloc[val_index]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m y_train, y_val \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[train_index], y\u001b[39m.\u001b[39miloc[val_index]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m           y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m           eval_set \u001b[39m=\u001b[39m [(X_val, y_val)],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m           verbose \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m best_iteration \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_booster()\u001b[39m.\u001b[39mbest_ntree_limit\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kimhakhyun/Desktop/Git/kaggle_playground/Kaggle_Playground/code/train.ipynb#W4sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m y_pred_proba \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(X_val, ntree_limit\u001b[39m=\u001b[39mbest_iteration)[:,\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_study = optimize_hyperparameters(xgb_objective, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_hyperparams =  {\n",
    "    'n_estimators'          : 2048,\n",
    "    'max_depth'             : 9,\n",
    "    'learning_rate'         : 0.05,\n",
    "    'booster'               : 'gbtree',\n",
    "    'subsample'             : 0.75,\n",
    "    'colsample_bytree'      : 0.30,\n",
    "    'reg_lambda'            : 1.00,\n",
    "    'reg_alpha'             : 1.00,\n",
    "    'gamma'                 : 1.00,\n",
    "    'random_state'          : SEED,\n",
    "    'objective'             : 'binary:logistic',\n",
    "    'tree_method'           : 'hist',\n",
    "    'eval_metric'           : 'auc',\n",
    "    'n_jobs'                : -1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['smoking'], axis=1)\n",
    "y_train = train_df['smoking']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = xgb.XGBClassifier(**best_lgbm_hyperparams)\n",
    "lgbm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.3, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=1.0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2048, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=578, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.3, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=1.0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2048, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=578, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.3, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
       "              gamma=1.0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=2048, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=578, ...)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(**best_xgb_hyperparams)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df\n",
    "y_pred = final_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('../submission/sample_submission.csv')\n",
    "submission_df['smoking'] = y_pred\n",
    "submission_df.to_csv(f'../submission/{final_model}_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pseudo-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pseudo_set(cutoff):\n",
    "    test_df['pred'] = y_pred\n",
    "\n",
    "    pseudo_set_1 = test_df[test_df['pred'] > cutoff]\n",
    "    pseudo_set_1['smoking'] = 1\n",
    "    pseudo_set_1.drop(['pred'], axis=1, inplace=True)\n",
    "\n",
    "    pseudo_set_2 = test_df[test_df['pred'] < 1-cutoff]\n",
    "    pseudo_set_2['smoking'] = 0\n",
    "    pseudo_set_2.drop(['pred'], axis=1, inplace=True)\n",
    "\n",
    "    pseudo_df = pd.concat([pseudo_set_1,pseudo_set_2])\n",
    "\n",
    "    return pseudo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xj/_swws2td1j333fqkjhr5tmjr0000gn/T/ipykernel_1638/3209239824.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pseudo_set_1['smoking'] = 1\n",
      "/var/folders/xj/_swws2td1j333fqkjhr5tmjr0000gn/T/ipykernel_1638/3209239824.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pseudo_set_1.drop(columns=['pred'], axis = 1, inplace=True)\n",
      "/var/folders/xj/_swws2td1j333fqkjhr5tmjr0000gn/T/ipykernel_1638/3209239824.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pseudo_set_2['smoking'] = 0\n",
      "/var/folders/xj/_swws2td1j333fqkjhr5tmjr0000gn/T/ipykernel_1638/3209239824.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pseudo_set_2.drop(columns=['pred'], axis = 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "pseudo_df = make_pseudo_set(0.95)\n",
    "pseudo_train_df = pd.concat([train_df, pseudo_df])\n",
    "\n",
    "X_pseudo_train = pseudo_train_df.drop(['smoking'], axis=1)\n",
    "y_pseudo_train = pseudo_train_df['smoking']\n",
    " \n",
    "pseudo_model = xgb.XGBClassifier(**best_xgb_hyperparams)\n",
    "pseudo_model.fit(X_pseudo_train, y_pseudo_train)\n",
    "\n",
    "submission_df = pd.read_csv('../submission/sample_submission.csv')\n",
    "submission_df['smoking'] =  pseudo_model.predict_proba(test_df.drop(['smoking'], axis=1))[:,1]\n",
    "submission_df.to_csv('../submission/pseudo_xgb_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
