{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "SEED = 578\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/preprocess_train.csv', index_col=0)\n",
    "valid_df = pd.read_csv('../data/preprocess_valid.csv', index_col=0)\n",
    "test_df = pd.read_csv('../data/preprocess_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optuna hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def optimize_hyperparameters(objective, n_trials):\n",
    "#     optuna.logging.set_verbosity(optuna.logging.CRITICAL)\n",
    "#     study = optuna.create_study(direction = \"maximize\")\n",
    "#     study.optimize(objective, n_trials=n_trials)\n",
    "#     print(\"Total Trials:\", len(study.trials))\n",
    "#     print(\"Best Score:\", study.best_value)\n",
    "#     print(\"Best Parameters:\", study.best_params)\n",
    "#     return study\n",
    "\n",
    "# def plot_study(study):\n",
    "#     optuna.visualization._get_intermediate_plot(study)\n",
    "#     optuna.visualization._get_slice_plot(study)\n",
    "#     optuna.visualization.plot_optimization_history(study)\n",
    "#     optuna.visualization.plot_parallel_coordinate(study)\n",
    "#     optuna.visualization.plot_contour(study)\n",
    "#     optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lgbm_objective(trial):\n",
    "#     hyperparams = {\n",
    "#         'n_estimators' : trial.suggest_int('n_estimators',500,1000),\n",
    "#         \"max_depth\":trial.suggest_int('max_depth',3,50),\n",
    "#         \"learning_rate\" : trial.suggest_float('learning_rate',1e-4,0.25,log=True),\n",
    "#         \"min_child_weight\" : trial.suggest_float('min_child_weight',0.5,4),\n",
    "#         \"min_child_samples\" : trial.suggest_int('min_child_samples',1,250),\n",
    "#         \"subsample\" : trial.suggest_float('subsample',0.2,1),\n",
    "#         \"subsample_freq\" : trial.suggest_int('subsample_freq',0,5),\n",
    "#         \"colsample_bytree\" : trial.suggest_float('colsample_bytree',0.2,1),\n",
    "#         'num_leaves' : trial.suggest_int('num_leaves',2,128),\n",
    "#     }\n",
    "    \n",
    "#     X = train_df.drop(['smoking'], axis=1)\n",
    "#     y = train_df['smoking']\n",
    "\n",
    "#     lgbm_model = lgb.LGBMClassifier(**hyperparams, random_state=SEED)\n",
    "\n",
    "#     # aucs = cross_val_score(lgbm_model, X, y, cv = 5, scoring='roc_auc')\n",
    "#     # auc_mean = aucs.mean()\n",
    "\n",
    "#     # print(\"AUCs:\", aucs)\n",
    "#     # print(\"AUC Mean:\", auc_mean)\n",
    "\n",
    "#     train_folds = joblib.load('../fold/10_train_stratifiedkfolds.jl')\n",
    "#     train_fold_aucs = []\n",
    "\n",
    "#     for train_fold, (train_index, val_index) in enumerate(train_folds):\n",
    "#         print(f'Fold {train_fold} Training: ...\\n')\n",
    "#         X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "#         y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "#         lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "#         y_pred = lgbm_model.predict_proba(X_val)[:,1]\n",
    "        \n",
    "#         train_fold_auc = roc_auc_score(y_val, y_pred)\n",
    "#         train_fold_aucs.append(train_fold_auc)\n",
    "\n",
    "#     train_fold_auc_mean = sum(train_fold_aucs) / len(train_fold_aucs)\n",
    "\n",
    "#     print(\"AUCs:\", train_fold_aucs)\n",
    "#     print(\"AUC Mean:\", train_fold_auc_mean)\n",
    "\n",
    "#     return train_fold_auc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_study = optimize_hyperparameters(lgbm_objective, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgbm_hyperparams =  {\n",
    "      'n_estimators': 555,\n",
    "      'max_depth': 43,\n",
    "      'learning_rate': 0.007268707576420426, \n",
    "      'min_child_weight': 3.12991455545269, \n",
    "      'min_child_samples': 159, \n",
    "      'subsample': 0.6259017376430374, \n",
    "      'subsample_freq': 2, \n",
    "      'colsample_bytree': 0.4519524559914368, \n",
    "      'num_leaves': 68\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def xgb_objective(trial):\n",
    "#     hyperparams = {\n",
    "#         'n_estimators' : trial.suggest_int('n_estimators',500,750),\n",
    "#         'max_depth':  trial.suggest_int('max_depth',3,50),\n",
    "#         'min_child_weight': trial.suggest_float('min_child_weight',2,50),\n",
    "#         \"learning_rate\" : trial.suggest_float('learning_rate',1e-4,0.2,log=True),\n",
    "#         'subsample': trial.suggest_float('subsample',0.2,1),\n",
    "#         'gamma': trial.suggest_float(\"gamma\",1e-4,1.0),\n",
    "#         \"colsample_bytree\" : trial.suggest_float('colsample_bytree',0.2,1),\n",
    "#         \"colsample_bylevel\" : trial.suggest_float('colsample_bylevel',0.2,1),\n",
    "#         \"colsample_bynode\" : trial.suggest_float('colsample_bynode',0.2,1),\n",
    "#     }\n",
    "\n",
    "#     X = train_df.drop(['smoking'], axis=1)\n",
    "#     y = train_df['smoking']\n",
    "\n",
    "#     xgb_model = xgb.XGBClassifier(**hyperparams, random_state=SEED)\n",
    " \n",
    "#     train_folds = joblib.load('../fold/10_train_stratifiedkfolds.jl')\n",
    "#     train_fold_aucs = []\n",
    "\n",
    "#     for train_fold, (train_index, val_index) in enumerate(train_folds):\n",
    "#         print(f'Fold {train_fold} Training: ...\\n')\n",
    "#         X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "#         y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "#         xgb_model.fit(X_train, y_train)\n",
    "        \n",
    "#         y_pred = xgb_model.predict_proba(X_val)[:,1]\n",
    "        \n",
    "#         train_fold_auc = roc_auc_score(y_val, y_pred)\n",
    "#         train_fold_aucs.append(train_fold_auc)\n",
    "\n",
    "#     train_fold_auc_mean = sum(train_fold_aucs) / len(train_fold_aucs)\n",
    "\n",
    "#     print(\"AUCs:\", train_fold_aucs)\n",
    "#     print(\"AUC Mean:\", train_fold_auc_mean)\n",
    "\n",
    "#     return train_fold_auc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_study = optimize_hyperparameters(xgb_objective, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_hyperparams =  {\n",
    "      'n_estimators': 748, \n",
    "      'max_depth': 46, \n",
    "      'min_child_weight': 32.69774846647831, \n",
    "      'learning_rate': 0.0370498003558445, \n",
    "      'subsample': 0.8695796691153823, \n",
    "      'gamma': 0.597338372907374, \n",
    "      'colsample_bytree': 0.6865936901180945, \n",
    "      'colsample_bylevel': 0.551057156483749, \n",
    "      'colsample_bynode': 0.30581796867932687\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cb_objective(trial):\n",
    "#     hyperparams = {\n",
    "#         'iterations': trial.suggest_int('iterations',500,750),\n",
    "#         'depth': trial.suggest_int('depth',3,10),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate',1e-4,0.2,log=True),\n",
    "#         'random_strength': trial.suggest_int('random_strength',0,100),\n",
    "#         'bagging_temperature': trial.suggest_float('bagging_temperature',0,1),\n",
    "#         'l2_leaf_reg': trial.suggest_int('l2_leaf_reg',3,30),\n",
    "#         'border_count': trial.suggest_int('border_count',32,255),\n",
    "#         'scale_pos_weight': trial.suggest_float('scale_pos_weight',0.01,1.0),\n",
    "#     }\n",
    "    \n",
    "#     X = train_df.drop(['smoking'], axis=1)\n",
    "#     y = train_df['smoking']\n",
    "    \n",
    "#     catboost_model = cb.CatBoostClassifier(**hyperparams, random_seed=SEED)\n",
    "\n",
    "#     train_folds = joblib.load('../fold/10_train_stratifiedkfolds.jl')\n",
    "#     train_fold_aucs = []\n",
    "    \n",
    "#     for train_fold, (train_index, val_index) in enumerate(train_folds):\n",
    "#         print(f'Fold {train_fold} Training: ...\\n')\n",
    "#         X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "#         y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "#         catboost_model.fit(X_train, y_train)\n",
    "        \n",
    "#         y_pred = catboost_model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "#         train_fold_auc = roc_auc_score(y_val, y_pred)\n",
    "#         train_fold_aucs.append(train_fold_auc)\n",
    "\n",
    "#     train_fold_auc_mean = sum(train_fold_aucs) / len(train_fold_aucs)\n",
    "\n",
    "#     print(\"AUCs:\", train_fold_aucs)\n",
    "#     print(\"AUC Mean:\", train_fold_auc_mean)\n",
    "    \n",
    "#     return train_fold_auc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_study = optimize_hyperparameters(cb_objective, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cb_hyperparams =  {\n",
    "      'iterations': 593,\n",
    "      'depth': 4,\n",
    "      'learning_rate': 0.12259905637676717,\n",
    "      'random_strength': 62,\n",
    "      'bagging_temperature': 0.2083824448364907,\n",
    "      'l2_leaf_reg': 26,\n",
    "      'border_count': 142,\n",
    "      'scale_pos_weight': 0.7204495417194038\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['smoking'], axis=1)\n",
    "y_train = train_df['smoking']\n",
    "\n",
    "X_valid = valid_df.drop(['smoking'], axis=1)\n",
    "y_valid = valid_df['smoking']\n",
    "\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    lgb.LGBMClassifier(**best_lgbm_hyperparams, random_state=SEED),\n",
    "    xgb.XGBClassifier(**best_xgb_hyperparams, random_state=SEED),\n",
    "    cb.CatBoostClassifier(**best_cb_hyperparams, random_state=SEED),\n",
    "]\n",
    "\n",
    "num_models = len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = joblib.load('../fold/10_train_stratifiedkfolds.jl')\n",
    "\n",
    "num_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_train = np.zeros((len(X_train), num_models))\n",
    "# preds_valid = np.zeros((len(X_valid), num_models))\n",
    "# preds_test = np.zeros((len(X_test), num_models))\n",
    "\n",
    "# for train_fold_idx, (t_idx, v_idx) in enumerate(train_folds):\n",
    "#     print(f'Fold {train_fold_idx} Training: ...\\n')\n",
    "#     X_t, y_t = X_train.iloc[t_idx], y_train.iloc[t_idx]\n",
    "#     X_v, y_v = X_train.iloc[v_idx], y_train.iloc[v_idx]\n",
    "\n",
    "#     for model_idx, model in enumerate(models):\n",
    "#         print(f'Model {model_idx} Fitting: ...\\n')\n",
    "#         model.fit(X_t, y_t)\n",
    "\n",
    "#         print(f'Model {model_idx} Predicting: ...\\n')\n",
    "#         pred_train = model.predict_proba(X_v)[:, 1]\n",
    "#         pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "#         pred_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         preds_train[v_idx, model_idx] = pred_train\n",
    "#         preds_valid[:, model_idx] += pred_valid / num_folds\n",
    "#         preds_test[:, model_idx] += pred_test / num_folds\n",
    "\n",
    "# np.save('../prediction/preds_train.npy', preds_train)\n",
    "# np.save('../prediction/preds_valid.npy', preds_valid)\n",
    "# np.save('../prediction/preds_test.npy', preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_idx in range(num_models):\n",
    "#     print(f'Model {model_idx} train AUC: = {roc_auc_score(y_train, preds_train[:, model_idx])}\\tvalid AUC:  = {roc_auc_score(y_valid, preds_valid[:, model_idx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = np.load('../prediction/preds_train.npy')\n",
    "preds_valid = np.load('../prediction/preds_valid.npy')\n",
    "preds_test = np.load('../prediction/preds_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RESULTS = {'Dataset': 'valid'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Index: 0\n"
     ]
    }
   ],
   "source": [
    "best_valid_score = float('-inf')\n",
    "best_model_idx = None\n",
    "\n",
    "for model_idx in range(num_models):\n",
    "    valid_score = roc_auc_score(y_valid, preds_valid[:, model_idx])\n",
    "    if valid_score > best_valid_score:\n",
    "        best_valid_score = valid_score\n",
    "        best_model_idx = model_idx\n",
    "\n",
    "print(f'Best Model Index: {best_model_idx}')\n",
    "VALID_RESULTS['Best Model'] = roc_auc_score(y_valid, preds_valid[:, best_model_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RESULTS['Best Model'] = roc_auc_score(y_valid, preds_valid[:, best_model_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RESULTS['Average'] = roc_auc_score(y_valid, preds_valid.mean(axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = [roc_auc_score(y_valid, preds_valid[:, model_idx]) for model_idx in range(num_models)]\n",
    "normalized_model_weights = model_weights / np.sum(model_weights)\n",
    "\n",
    "weighted_average_preds_train = np.average(preds_train, weights=normalized_model_weights, axis=1)\n",
    "weighted_average_preds_valid = np.average(preds_valid, weights=normalized_model_weights, axis=1)\n",
    "\n",
    "VALID_RESULTS['Weighted Average'] = roc_auc_score(y_valid, weighted_average_preds_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33588, number of negative: 45708\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 79296, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.423577 -> initscore=-0.308104\n",
      "[LightGBM] [Info] Start training from score -0.308104\n"
     ]
    }
   ],
   "source": [
    "stacking_model = lgb.LGBMClassifier(**best_lgbm_hyperparams, random_state=SEED)\n",
    "\n",
    "stacking_model.fit(preds_valid, y_valid)\n",
    "stacking_preds_valid = stacking_model.predict_proba(preds_valid)[:, 1]\n",
    "\n",
    "VALID_RESULTS['Stacking'] = roc_auc_score(y_valid, stacking_preds_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Best Model</th>\n",
       "      <th>Average</th>\n",
       "      <th>Weighted Average</th>\n",
       "      <th>Stacking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valid</td>\n",
       "      <td>0.845448</td>\n",
       "      <td>0.843696</td>\n",
       "      <td>0.843708</td>\n",
       "      <td>0.846987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Best Model   Average  Weighted Average  Stacking\n",
       "0   valid    0.845448  0.843696          0.843708  0.846987"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records([VALID_RESULTS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_preds_test = preds_test[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_preds_test = stacking_model.predict_proba(preds_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('../submission/sample_submission.csv')\n",
    "submission_df['smoking'] = stacking_preds_test\n",
    "submission_df.to_csv(f'../submission/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pseudo-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pseudo_set(cutoff):\n",
    "    test_df['pred'] = y_pred\n",
    "\n",
    "    pseudo_set_1 = test_df[test_df['pred'] > cutoff]\n",
    "    pseudo_set_1['smoking'] = 1\n",
    "    pseudo_set_1.drop(['pred'], axis=1, inplace=True)\n",
    "\n",
    "    pseudo_set_2 = test_df[test_df['pred'] < 1-cutoff]\n",
    "    pseudo_set_2['smoking'] = 0\n",
    "    pseudo_set_2.drop(['pred'], axis=1, inplace=True)\n",
    "\n",
    "    pseudo_df = pd.concat([pseudo_set_1,pseudo_set_2])\n",
    "\n",
    "    return pseudo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xj/_swws2td1j333fqkjhr5tmjr0000gn/T/ipykernel_1638/3209239824.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pseudo_set_1['smoking'] = 1\n",
      "/var/folders/xj/_swws2td1j333fqkjhr5tmjr0000gn/T/ipykernel_1638/3209239824.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pseudo_set_1.drop(columns=['pred'], axis = 1, inplace=True)\n",
      "/var/folders/xj/_swws2td1j333fqkjhr5tmjr0000gn/T/ipykernel_1638/3209239824.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pseudo_set_2['smoking'] = 0\n",
      "/var/folders/xj/_swws2td1j333fqkjhr5tmjr0000gn/T/ipykernel_1638/3209239824.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pseudo_set_2.drop(columns=['pred'], axis = 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "pseudo_df = make_pseudo_set(0.95)\n",
    "pseudo_train_df = pd.concat([train_df, pseudo_df])\n",
    "\n",
    "X_pseudo_train = pseudo_train_df.drop(['smoking'], axis=1)\n",
    "y_pseudo_train = pseudo_train_df['smoking']\n",
    " \n",
    "pseudo_model = xgb.XGBClassifier(**best_xgb_hyperparams)\n",
    "pseudo_model.fit(X_pseudo_train, y_pseudo_train)\n",
    "\n",
    "submission_df = pd.read_csv('../submission/sample_submission.csv')\n",
    "submission_df['smoking'] =  pseudo_model.predict_proba(test_df.drop(['smoking'], axis=1))[:,1]\n",
    "submission_df.to_csv('../submission/pseudo_xgb_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
